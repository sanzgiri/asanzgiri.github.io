{
  
    
        "post0": {
            "title": "Setup",
            "content": ". This Google Colab Notebook allows you to run the code in https://github.com/alex04072000/SingleHDR which is an implementation of the CVPR 2020 paper &quot;Single-Image HDR Reconstruction by Learning to Reverse the Camera Pipeline&quot;, which can be downloaded from https://arxiv.org/abs/2004.01179 . Ashutosh Sanzgiri sanzgiri@gmail.com | . !git clone https://github.com/alex04072000/SingleHDR . # The versions of packages needed was identified by crawling through github issues !pip install tensorflow==1.10.0 !pip install tensorlayer==1.10.1 # After installation restart runtime and continue with the next cell. . # Confirm you have the correct versions !pip list | grep tensor . tensorboard 1.10.0 tensorboard-plugin-wit 1.7.0 tensorboardcolab 0.0.22 tensorflow 1.10.0 tensorflow-addons 0.8.3 tensorflow-datasets 2.1.0 tensorflow-estimator 2.3.0 tensorflow-gcs-config 2.3.0 tensorflow-hub 0.9.0 tensorflow-metadata 0.24.0 tensorflow-privacy 0.2.2 tensorflow-probability 0.11.0 tensorlayer 1.10.1 . # This is needed to install the pre-trained models to local !pip install gdown . # This is one way to convert HDR files to LDR # http://pfstools.sourceforge.net/man_pages.html # http://pfstools.sourceforge.net/man_pages.html #!sudo apt-get install pfstools !sudo apt-get install --reinstall pfstools . # Another option to convert HDR to LDR is ImageMagick !sudo apt-get install imagemagick . # Autotone for tonemapping with ImageMagick !curl -o autotone &quot;http://www.fmwconcepts.com/imagemagick/downloadcounter.php?scriptname=autotone&amp;dirname=autotone&quot; !chmod +x autotone . # You can also use OpenCV !pip install opencv-python-headless . # And this function # Ref: https://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python/ # https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gabcbd653140b93a1fa87ccce94548cd0d # https://docs.opencv.org/4.0.0/d2/df0/tutorial_py_hdr.html # https://www.toptal.com/opencv/python-image-processing-in-computational-photography import cv2 import numpy as np from cv2 import createTonemapDrago, createTonemapMantiuk, createTonemapReinhard, createTonemap def convert_hdr(hdrfile, ldrfile, tm_choice=&quot;D&quot;, val=2.2): im = cv2.imread(hdrfile, cv2.IMREAD_ANYDEPTH) if tm_choice == &quot;D&quot;: tonemap = createTonemapDrago(gamma=val, bias=0.85) elif tm_choice == &quot;M&quot;: tonemap = createTonemapMantiuk(gamma=val, scale=0.75) elif tm_choice == &quot;R&quot;: tonemap = createTonemapReinhard(gamma=val) else: tonemap = createTonemap(gamma=val) ldr = tonemap.process(im) im2_8bit = np.clip(ldr * 255, 0, 255).astype(&#39;uint8&#39;) cv2.imwrite(ldrfile, im2_8bit) . # This is for plotting images side by side !pip install ipyplot . cd SingleHDR . /content/SingleHDR/SingleHDR . # Download models and unzip !gdown https://drive.google.com/uc?id=1e9vP8YPEjGcvXCa0Bfqwxw7qks7dH-VE !unzip -o ckpt.zip . Run test example using model trained on synthetic data . # Run test example (model trained only on synthetic data) # Ignore the tmalloc errors # Note output file has .hdr extension, some image viewers like Mac Preview can open it. You can convert it to .png as shown below !CUDA_VISIBLEDEVICES=0 python3 test_real.py --ckpt_path_deq ckpt_deq/model.ckpt --ckpt_path_lin ckpt_lin/model.ckpt --ckpt_path_hal ckpt_hal/model.ckpt --test_imgs ./imgs --output_path output_hdrs . # Original image !ls -l imgs . total 2892 -rw-r--r-- 1 root root 2961073 Sep 25 22:35 00000.png . # HDR version !ls -l output_hdrs . total 5544 -rw-r--r-- 1 root root 5676415 Sep 25 22:38 00000.hdr . Explore various ways to convert HDR to LDR . # Convert HDR to PNG using pfstools !pfsin output_hdrs/00000.hdr | pfstmo_drago03 | pfsout output_hdrs/00000_hdr_pfs.png . # Convert HDR image to PNG using imagemagick !convert output_hdrs/00000.hdr output_hdrs/00000_hdr_im.png # Autotone it! !./autotone output_hdrs/00000.hdr output_hdrs/00000_hdr_im.png . # Convert HDR image to PNG using openCV convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_d.png&#39;, &#39;D&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_m.png&#39;, &#39;M&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_r.png&#39;, &#39;R&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_u.png&#39;, &#39;U&#39;, 2.2) . Comparisons . PFSTools . # Compare original with HDR version import ipyplot ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_pfs.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_pfs.png . ImageMagick with Autotone is the best choice! . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_im.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_im.png . OpenCV options . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_d.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_d.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_m.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_m.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_r.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_r.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_u.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_u.png . Run test example on model trained with Real + Synthetic data . # Run test example (model trained only on real + synthetic data) # Ignore the tmalloc errors # Note output file has .hdr extension, but can be opened by image viewer such as preview # this is better quality !CUDA_VISIBLEDEVICES=0 python3 test_real_refinement.py --ckpt_path ckpt_deq_lin_hal_ref/model.ckpt --test_imgs ./imgs --output_path output_hdrs2 . !pfsin output_hdrs2/00000.hdr | pfstmo_drago03| pfsout output_hdrs2/00000_hdr.png ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs2/00000_hdr.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs2/00000_hdr.png . Upload your own file now . !mkdir -p uploads !mv /landscape.png uploads . !CUDA_VISIBLEDEVICES=0 python3 test_real_refinement.py --ckpt_path ckpt_deq_lin_hal_ref/model.ckpt --test_imgs ./uploads --output_path output_hdrs . # Convert to HDR &amp; Autotone it! !./autotone output_hdrs/landscape.hdr output_hdrs/landscape_hdr_im.png ipyplot.plot_images([&#39;uploads/landscape.png&#39;, &#39;output_hdrs/landscape_hdr_im.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_im.png . # Convert HDR to PNG using pfstools !pfsin output_hdrs/landscape.hdr | pfstmo_drago03 | pfsout output_hdrs/landscape_hdr_pfs.png ipyplot.plot_images([&#39;uploads/landscape.png&#39;, &#39;output_hdrs/landscape_hdr_pfs.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_pfs.png . # Convert HDR image to PNG using opencv origfile = &#39;uploads/landscape.png&#39; hdrfile = &#39;output_hdrs/landscape.hdr&#39; for tonemap in [&#39;D&#39;, &#39;M&#39;, &#39;R&#39;, &#39;U&#39;]: outfile = f&#39;output_hdrs/landscape_hdr_cv_{tonemap}.png&#39; convert_hdr(hdrfile, outfile, &#39;D&#39;, 2.2) ipyplot.plot_images([origfile, outfile], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_D.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_M.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_R.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_U.png .",
            "url": "https://sanzgiri.com/2020/09/25/Single_HDR.html",
            "relUrl": "/2020/09/25/Single_HDR.html",
            "date": " • Sep 25, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Setup",
            "content": ". This Google Colab Notebook allows you to run the code in https://github.com/alex04072000/SingleHDR which is an implementation of the CVPR 2020 paper &quot;Single-Image HDR Reconstruction by Learning to Reverse the Camera Pipeline&quot;, which can be downloaded from https://arxiv.org/abs/2004.01179 . Ashutosh Sanzgiri sanzgiri@gmail.com | . !git clone https://github.com/alex04072000/SingleHDR . # The versions of packages needed was identified by crawling through github issues !pip install tensorflow==1.10.0 !pip install tensorlayer==1.10.1 # After installation restart runtime and continue with the next cell. . # Confirm you have the correct versions !pip list | grep tensor . tensorboard 1.10.0 tensorboard-plugin-wit 1.7.0 tensorboardcolab 0.0.22 tensorflow 1.10.0 tensorflow-addons 0.8.3 tensorflow-datasets 2.1.0 tensorflow-estimator 2.3.0 tensorflow-gcs-config 2.3.0 tensorflow-hub 0.9.0 tensorflow-metadata 0.24.0 tensorflow-privacy 0.2.2 tensorflow-probability 0.11.0 tensorlayer 1.10.1 . # This is needed to install the pre-trained models to local !pip install gdown . # This is one way to convert HDR files to LDR # http://pfstools.sourceforge.net/man_pages.html # http://pfstools.sourceforge.net/man_pages.html #!sudo apt-get install pfstools !sudo apt-get install --reinstall pfstools . # Another option to convert HDR to LDR is ImageMagick !sudo apt-get install imagemagick . # Autotone for tonemapping with ImageMagick !curl -o autotone &quot;http://www.fmwconcepts.com/imagemagick/downloadcounter.php?scriptname=autotone&amp;dirname=autotone&quot; !chmod +x autotone . # You can also use OpenCV !pip install opencv-python-headless . # And this function # Ref: https://www.learnopencv.com/high-dynamic-range-hdr-imaging-using-opencv-cpp-python/ # https://docs.opencv.org/master/d6/df5/group__photo__hdr.html#gabcbd653140b93a1fa87ccce94548cd0d # https://docs.opencv.org/4.0.0/d2/df0/tutorial_py_hdr.html # https://www.toptal.com/opencv/python-image-processing-in-computational-photography import cv2 import numpy as np from cv2 import createTonemapDrago, createTonemapMantiuk, createTonemapReinhard, createTonemap def convert_hdr(hdrfile, ldrfile, tm_choice=&quot;D&quot;, val=2.2): im = cv2.imread(hdrfile, cv2.IMREAD_ANYDEPTH) if tm_choice == &quot;D&quot;: tonemap = createTonemapDrago(gamma=val, bias=0.85) elif tm_choice == &quot;M&quot;: tonemap = createTonemapMantiuk(gamma=val, scale=0.75) elif tm_choice == &quot;R&quot;: tonemap = createTonemapReinhard(gamma=val) else: tonemap = createTonemap(gamma=val) ldr = tonemap.process(im) im2_8bit = np.clip(ldr * 255, 0, 255).astype(&#39;uint8&#39;) cv2.imwrite(ldrfile, im2_8bit) . # This is for plotting images side by side !pip install ipyplot . cd SingleHDR . /content/SingleHDR/SingleHDR . # Download models and unzip !gdown https://drive.google.com/uc?id=1e9vP8YPEjGcvXCa0Bfqwxw7qks7dH-VE !unzip -o ckpt.zip . Run test example using model trained on synthetic data . # Run test example (model trained only on synthetic data) # Ignore the tmalloc errors # Note output file has .hdr extension, some image viewers like Mac Preview can open it. You can convert it to .png as shown below !CUDA_VISIBLEDEVICES=0 python3 test_real.py --ckpt_path_deq ckpt_deq/model.ckpt --ckpt_path_lin ckpt_lin/model.ckpt --ckpt_path_hal ckpt_hal/model.ckpt --test_imgs ./imgs --output_path output_hdrs . # Original image !ls -l imgs . total 2892 -rw-r--r-- 1 root root 2961073 Sep 25 22:35 00000.png . # HDR version !ls -l output_hdrs . total 5544 -rw-r--r-- 1 root root 5676415 Sep 25 22:38 00000.hdr . Explore various ways to convert HDR to LDR . # Convert HDR to PNG using pfstools !pfsin output_hdrs/00000.hdr | pfstmo_drago03 | pfsout output_hdrs/00000_hdr_pfs.png . # Convert HDR image to PNG using imagemagick !convert output_hdrs/00000.hdr output_hdrs/00000_hdr_im.png # Autotone it! !./autotone output_hdrs/00000.hdr output_hdrs/00000_hdr_im.png . # Convert HDR image to PNG using openCV convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_d.png&#39;, &#39;D&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_m.png&#39;, &#39;M&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_r.png&#39;, &#39;R&#39;, 2.2) convert_hdr(&#39;output_hdrs/00000.hdr&#39;, &#39;output_hdrs/00000_hdr_cv_u.png&#39;, &#39;U&#39;, 2.2) . Comparisons . PFSTools . # Compare original with HDR version import ipyplot ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_pfs.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_pfs.png . ImageMagick with Autotone is the best choice! . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_im.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_im.png . OpenCV options . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_d.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_d.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_m.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_m.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_r.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_r.png . ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs/00000_hdr_cv_u.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs/00000_hdr_cv_u.png . Run test example on model trained with Real + Synthetic data . # Run test example (model trained only on real + synthetic data) # Ignore the tmalloc errors # Note output file has .hdr extension, but can be opened by image viewer such as preview # this is better quality !CUDA_VISIBLEDEVICES=0 python3 test_real_refinement.py --ckpt_path ckpt_deq_lin_hal_ref/model.ckpt --test_imgs ./imgs --output_path output_hdrs2 . !pfsin output_hdrs2/00000.hdr | pfstmo_drago03| pfsout output_hdrs2/00000_hdr.png ipyplot.plot_images([&#39;imgs/00000.png&#39;, &#39;output_hdrs2/00000_hdr.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . imgs/00000.png . 1 . output_hdrs2/00000_hdr.png . Upload your own file now . !mkdir -p uploads !mv /landscape.png uploads . !CUDA_VISIBLEDEVICES=0 python3 test_real_refinement.py --ckpt_path ckpt_deq_lin_hal_ref/model.ckpt --test_imgs ./uploads --output_path output_hdrs . # Convert to HDR &amp; Autotone it! !./autotone output_hdrs/landscape.hdr output_hdrs/landscape_hdr_im.png ipyplot.plot_images([&#39;uploads/landscape.png&#39;, &#39;output_hdrs/landscape_hdr_im.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_im.png . # Convert HDR to PNG using pfstools !pfsin output_hdrs/landscape.hdr | pfstmo_drago03 | pfsout output_hdrs/landscape_hdr_pfs.png ipyplot.plot_images([&#39;uploads/landscape.png&#39;, &#39;output_hdrs/landscape_hdr_pfs.png&#39;], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_pfs.png . # Convert HDR image to PNG using opencv origfile = &#39;uploads/landscape.png&#39; hdrfile = &#39;output_hdrs/landscape.hdr&#39; for tonemap in [&#39;D&#39;, &#39;M&#39;, &#39;R&#39;, &#39;U&#39;]: outfile = f&#39;output_hdrs/landscape_hdr_cv_{tonemap}.png&#39; convert_hdr(hdrfile, outfile, &#39;D&#39;, 2.2) ipyplot.plot_images([origfile, outfile], max_images=2, img_width=600, force_b64=True) . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_D.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_M.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_R.png . 0 . uploads/landscape.png . 1 . output_hdrs/landscape_hdr_cv_U.png .",
            "url": "https://sanzgiri.com/2020/09/24/Single-HDR.html",
            "relUrl": "/2020/09/24/Single-HDR.html",
            "date": " • Sep 24, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Home Automation with a Raspberry Pi",
            "content": "I had come across Home Assistant a while back, and finally set it up this weekend. It was pretty quick and easy. . I ordered the Canakit Raspberrry Pi 4 8 GB Extreme Kit from Amazon. The full list of supported hardware can be found in the Home Assistant Installation instructions. . There are a couple of things to be done differently for a Pi 4: . I used the latest build Development 5, Release 1, specifically the 64-bit version (hassos_rpi4-64-5.1.img.gz) . | As described in the instructions, I set up the WiFi using a blank USB stick (FAT 32 format, volume label CONFIG) with a file /network/my-network with the contents shown here: the example under “Wireless LAN WPA/PSK”. Only lines to change here are the ssid and psk settings for ure wireless LAN. . | That was it. After rebooting you can access your Home Assistant at http://homeassistant.local:8123 . | .",
            "url": "https://sanzgiri.com/automation/iot/2020/08/23/home-assistant.html",
            "relUrl": "/automation/iot/2020/08/23/home-assistant.html",
            "date": " • Aug 23, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Creating auto-updating notebooks and blog posts with FastPages",
            "content": "Assumes you have a blog set up using FastPages. If not, you can quickly create one going through the steps listed here. Note that you can create multiple FastPages blogs inside your github account, each in a separate repo. . | Add an update-nb.yaml file to directory &lt;repo&gt;.github/workflows in your blog repo. Starting points for this file are: update-nb.yaml template (or a trimmed version here that does not use issues to trigger or monitor your workflow: my trimmed template . The only things to change here are the cron schedule (question - can you set up a separate schedule by notebook?) . | Update the install dependencies section with any steps you need for your notebooks to run . | . | Add run_notebooks.sh to directory &lt;repo&gt;/_action_files. The template I started with was: run_notebooks.sh template . In this file you can control which notebooks get updated on the schedule you have set up. | . | Add the notebooks to directory &lt;repo&gt;/_notebooks. Specific rules for how to customize your notebook so that it looks “good” when coverted to a blog post can be seen here: Notebook commands for FastPages . | That is basically it! Once these code changes are checked in, Github Actions will get scheduled per your cron settings in update-nb.yaml. You can monitor the actions from the Actions link in the toolbar at the top of the github link for your repo. You can view the steps inside the Update Notebooks And Refresh Page action. If there are any errors, the messages are pretty explanatory. . | . References . Github Actions | .",
            "url": "https://sanzgiri.com/jupyter/2020/04/15/fastpages-jupyter-notebooks.html",
            "relUrl": "/jupyter/2020/04/15/fastpages-jupyter-notebooks.html",
            "date": " • Apr 15, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sanzgiri.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Grab Url Screenshot",
            "content": ". title: “Grab URL Screenshot” description: “Grab URL Screenshot” layout: post toc: false comments: true hide: false search_exclude: false categories: [automation, scraping] . Grab a screenshot of web page using a “headless” chrome browser | . # Install chrome sudo sh -c &#39;echo &quot;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&quot; &gt;&gt; /etc/apt/sources.list.d/google.list&#39; sudo apt-get update sudo apt-get install google-chrome-stable # Find version of chrome google-chrome --version # Find corresponding version of chromedriver from here: https://sites.google.com/a/chromium.org/chromedriver/downloads # and then here: https://chromedriver.storage.googleapis.com/index.html and download wget https://chromedriver.storage.googleapis.com/&lt;version&gt;/chromedriver_linux64.zip unzip chromedriver_linux64.zip sudo mv chromedriver /usr/bin # Install selenium webdriver pip install selenium . from selenium import webdriver # Import selenium web driver from IPython.display import Image def get_screenshot(url, imagefile): chrome_options = webdriver.ChromeOptions() chrome_options.add_argument(&#39;--headless&#39;) driver = webdriver.Chrome(&#39;chromedriver&#39;, options=chrome_options) driver.get(url) res = driver.save_screenshot(imagefile) if res: print(f&#39;URL screenshot for {url} saved to {imagefile}&#39;) else: print(&#39;Error getting URL screenshot&#39;) . get_screenshot(&#39;https://phantomjs.org/screen-capture.html&#39;, &#39;p2.png&#39;) Image(filename=&#39;p2.png&#39;) . URL screenshot for https://phantomjs.org/screen-capture.html saved to p2.png | . .",
            "url": "https://sanzgiri.com/2020/01/29/Grab-URL-screenshot.html",
            "relUrl": "/2020/01/29/Grab-URL-screenshot.html",
            "date": " • Jan 29, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Deploy Streamlit to Heroku",
            "content": "Deploy streamlit app to Heroku (on mac) . # Install heroku brew install heroku/brew/heroku # Setup autocomplete for heroku heroku autocomplete # The app you are deploying has to be in a github repo (private is ok). An example repo is # https://github.com/MaartenGr/streamlit_guide.git # The repo should contain a Procfile, a setup.sh file and requirements.txt containing any package dependencies # The streamlit app should be named app.py and in the root directory. These are the must have files # Steps to deploy your app heroku login # This sets up the heroku remote heroku create # Push code and trigger an action that launches your app git push heroku master # Scale app runtine for free usage heroku ps:scale web=1 # Connect to your app on xxx.herokuapp.com heroku open # To rename app from xxx.herokuapp.com to newname.herokuapp.com, change app name in settings, then from local repo git remote rm heroku heroku git:remote -a &lt;newname&gt; # To setup custom domain e.g. easyai.ml heroku domains add:www.easyai.ml. # subdomain heroku domains add:easyai.ml. # root domain heroku domains # list dns record types and targets # Add CNAME entry for subdomain with name www, TTL 300 and target of form xxx.herokudns.com (no trailing dot) # Add CNAME entry for root domain with name www, TTL 300 and target of form xxx.herokudns.com (no trailing dot) # To confirm setup is complete. Changes will take some time to propagate host www.easyai.ml host easyai.ml # Each of the commands above should say that &lt;host&gt; is an alias for &lt;xxx.herokudns.com&gt; .",
            "url": "https://sanzgiri.com/Deploy-streamlit-to-Heroku-2019-12-20",
            "relUrl": "/Deploy-streamlit-to-Heroku-2019-12-20",
            "date": " • Dec 19, 2019"
        }
        
    
  
    
        ,"post7": {
            "title": "Weekly Update, November 26, 2019",
            "content": "Updates from week of November 26, 2019 . Gilbert Strang playlist on MIT OCW (Matrix Algebra): https://www.youtube.com/playlist?list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k | The 100 page ML Book: http://themlbook.com/wiki/doku.php?id=start | Clean Code ML repo: https://github.com/davified/clean-code-ml | Transformers: Simple Transformers Blog https://medium.com/swlh/simple-transformers-multi-class-text-classification-with-bert-roberta-xlnet-xlm-and-8b585000ce3a | Repo: https://github.com/ThilinaRajapakse/simpletransformers | Nvidia Apex https://github.com/NVIDIA/apex | Hugging Face: Blog: https://medium.com/tensorflow/using-tensorflow-2-for-state-of-the-art-natural-language-processing-102445cda54a, Examples: https://github.com/huggingface/transformers/tree/master/examples, Docs: https://huggingface.co/transformers/quickstart.html | Illustrated BERT: http://jalammar.github.io/illustrated-bert/ | Allen NLP: https://github.com/allenai/allennlp | . | Financial Models: Notebook collection https://github.com/cantaro86/Financial-Models-Numerical-Methods, in particular one on Kalman filters: https://github.com/cantaro86/Financial-Models-Numerical-Methods/blob/master/5.1%20Linear%20regression%20-%20Kalman%20filter.ipynb | Another gem on Kalman filters: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python and PDF https://drive.google.com/file/d/0By_SW19c1BfhSVFzNHc0SjduNzg/view | . | Data Sampling in Presto: https://ragrawal.wordpress.com/2017/08/11/data-sampling-in-presto/ | Clean Pytorch implementation of Style Transfer: https://github.com/shivamswarnkar/Style-Transfer/tree/871b2607d68d7dfa46c0242e4fdd9e98f77bbd93 | Kaggle class on TWIML AI: Github: https://github.com/philpackmohr/kaggle-twimlai | Kaggle Winning Solutions &amp; Pipeline: http://kagglesolutions.com/r/?ref=headerlinkh | Incredible Glossary: https://www.kaggle.com/shivamb/data-science-glossary-on-kaggle/ | Winning Kaggle Solutions: https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions/notebook | Short clean kernel: https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s | Pavel Pleskov secrets: https://www.youtube.com/watch?v=fXnzjJMbujc | Model stacking (Kaggle Blog): http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/ | No Free Hunch: http://blog.kaggle.com/ | Feature Selection via Target Permutations: https://www.kaggle.com/ogrellier/feature-selection-target-permutations and https://www.kaggle.com/ogrellier/feature-selection-with-null-importances | Feature Importances: https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3 | Slidedecks with tricks: https://www.slideshare.net/markpeng/general-tips-for-participating-kaggle-competitions, https://www.slideshare.net/HJvanVeen/kaggle-presentation?qid=9945759e-a06f-447d-bcfb-2a15592f30b6&amp;v=&amp;b=&amp;from_search=11, https://www.slideshare.net/DariusBaruauskas/tips-and-tricks-to-win-kaggle-data-science-competitions?qid=2ea2c741-a9af-4c84-9292-d11725c0c68c&amp;v=&amp;b=&amp;from_search=5, https://www.slideshare.net/gabrielspmoreira/feature-engineering-getting-most-out-of-data-for-predictive-models-tdc-2017, https://www.slideshare.net/jeongyoonlee/winning-data-science-competitions-74391113 | Good AMA: https://towardsdatascience.com/ask-me-anything-session-with-a-kaggle-grandmaster-vladimir-i-iglovikov-942ad6a06acd | . | MLCourse.ai: Resources: https://mlcourse.ai/resources | Kernels: https://www.kaggle.com/kashnitsky/mlcourse/kernels | Github: https://github.com/Yorko/mlcourse.ai | Open Data Science courses: https://medium.com/open-machine-learning-course | . | Optuna vs HyperOpt: https://neptune.ml/blog/optuna-vs-hyperopt | Free PyTorch Intro Book: https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf | Makefiles everywhere: https://blog.mindlessness.life/makefile/2019/11/17/the-language-agnostic-all-purpose-incredible-makefile.html | DVC for model version control: https://dvc.org/ | Eli5 Model Explainability: https://github.com/TeamHG-Memex/eli5 | Autoencoders: https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases | .",
            "url": "https://sanzgiri.com/weekly-update-112619",
            "relUrl": "/weekly-update-112619",
            "date": " • Nov 25, 2019"
        }
        
    
  
    
        ,"post8": {
            "title": "Weekly Update, October 31, 2019",
            "content": "Updates from week of October 31, 2019 . Top 10 SQL Tricks: https://blog.jooq.org/2016/04/25/10-sql-tricks-that-you-didnt-think-were-possible/ | Portland Area ML Resources: https://github.com/jimtyhurst/ml-resources-Portland-OR-USA/blob/master/ml-resources-Portland-OR-USA.md | Interpretable ML: https://christophm.github.io/interpretable-ml-book/ | Bert Word Embeddings Tutorial: https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ | Swifter: https://towardsdatascience.com/one-word-of-code-to-stop-using-pandas-so-slowly-793e0a81343c &amp; https://github.com/jmcarpenter2/swifter | Cross-Validated fun facts: https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn | Top posts by score (score&gt;400): https://stats.stackexchange.com/search?q=score%3A400 | Top posts by views (views&gt;400000): https://stats.stackexchange.com/search?q=views%3A400000 | . | Streamlit: https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace | Cron jobs in AWS: https://medium.com/better-programming/cron-job-patterns-in-aws-126fbf54a276 | No surprise - Feather is the best format for data storage in pandas: https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d | Robo Advisors in Python: https://towardsdatascience.com/python-for-finance-stock-portfolio-analyses-6da4c3e61054 | Pandas Profiling package (One line EDA): https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82d | Spleeter: Free Music Separation: https://waxy.org/2019/11/fast-and-free-music-separation-with-deezers-machine-learning-library | Jovian.ml https://jovian-py.readthedocs.io/en/latest/ | Pachyderm (Hub Beta) https://www.pachyderm.com/ | Francois Chollet - The Measure of Intelligence: https://arxiv.org/pdf/1911.01547.pdf | LibFM http://arogozhnikov.github.io/2016/02/15/TestingLibFM.html FastFM tutorial: http://ibayer.github.io/fastFM/index.html | . | Home Assistant https://www.home-assistant.io/ | .",
            "url": "https://sanzgiri.com/weekly-update-103119",
            "relUrl": "/weekly-update-103119",
            "date": " • Sep 19, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "Weekly Update, September 27, 2019",
            "content": "Updates from week of September 27, 2019 . Using FeatureTools https://docs.featuretools.com/index.html + AutoML (H2O) http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html | Tutorial from Analytics Vidhya https://www.analyticsvidhya.com/blog/2018/08/guide-automated-feature-engineering-featuretools-python/ | AutoML: https://medium.com/@alxmamaev/how-to-build-automl-from-scratch-ce45a4b51e0f | ML-Workspace: https://github.com/ml-tooling/ml-workspace/ | Kaggle Youtube-8m 2019 challenge https://www.kaggle.com/c/youtube8m-2019/overview | Kaggle Scripting Contest submissions: https://www.kaggle.com/general/109651 | Pandas EDA: https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82d | RAdam for tensorflow &amp; keras https://pypi.org/project/tensorflow-radam/ | Customer Lifetime Value: https://medium.com/@josh.temple/how-to-estimate-the-value-of-your-customers-the-right-way-57c63fad093 | Lifetimes package: https://github.com/CamDavidsonPilon/lifetimes https://lifetimes.readthedocs.io/en/latest/Quickstart.html | Bruce Hardie: http://brucehardie.com/ | Model Ensembling: | Stacking Made Easy http://blog.kaggle.com/2017/06/15/stacking-made-easy-an-introduction-to-stacknet-by-competitions-grandmaster-marios-michailidis-kazanova/ | Kaggle Ensembling Guide https://mlwave.com/kaggle-ensembling-guide/ | PyStackNet: https://github.com/h2oai/pystacknet | Intro to Stacking https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python | 30 seconds of Python: https://github.com/30-seconds/30-seconds-of-python | Streamlit: https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace | .",
            "url": "https://sanzgiri.com/weekly-update-092719",
            "relUrl": "/weekly-update-092719",
            "date": " • Sep 19, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Weekly Update, September 20, 2019",
            "content": "Updates from week of September 20, 2019 . Acing AI: AI interview questions collection: https://medium.com/acing-ai | Getting started with Algo Trading: https://www.quantstart.com/articles | Making custom text with GPT-2: https://minimaxir.com/2019/09/howto-gpt2/ | Actionable Book Summaries: https://durmonski.com/book-summaries/ | .",
            "url": "https://sanzgiri.com/weekly-update-092019",
            "relUrl": "/weekly-update-092019",
            "date": " • Sep 19, 2019"
        }
        
    
  
    
        ,"post11": {
            "title": "Hack to read Medium articles for free!",
            "content": "How to read Medium blog posts &amp; other paywalled articles for free! . Medium: . Note - do this at your own risk! The “Mediumship” Chrome extension (created by the author of the git repo described below) was removed from the Chrome Extension store a few months ago. There is a similar extension called “Medium Free” that is still available on the Firefox plugin store. . Clone this git repo https://github.com/swapagarwal/mediumship . | Go to &lt;chrome://extensions&gt;. Click the “Load Unpacked” button and point to the “chrome” directory underneath the directory in which the “mediumship” repo was downloaded. . | Voila! You now have the Mediumship extension installed. Click on this while viewing a Medium post that is behind a membership wall and it will open up as readable in a new tab. . | Btw - here’s a good reference on creating a chrome extension: https://thoughtbot.com/blog/how-to-make-a-chrome-extension . | Also, if you don’t want to go this route - just tweet the medium URL from your account and access the URL from your feed. . | I ended up not using this and resuming my Medium subscription, because this approach does not work on my iPhone (iOS Chrome browser does not support extensions. apparently Firefox does and the “Yandex” version of Chrome does, but I haven’t tried this) . | . MIT tech Review, NYT, Economist, Business Insider, Washington Post, Boston Globe . Just “block Javascript” for the corresponding site in your desktop browser. e.g. for Chrome, click on the lock icon to the left on the URL, go to Site Settings and under Javascript, select “Block”. This hack comes from https://hackernoon.com/how-i-hacked-the-mit-technology-review-website-many-more-and-gained-unlimited-online-access-e89a57cdc248. The author has reported this website flaw to the site admins, so it might get corrected soon. . | Have not tried this on my iPhone. . | .",
            "url": "https://sanzgiri.com/membership",
            "relUrl": "/membership",
            "date": " • Aug 26, 2019"
        }
        
    
  
    
        ,"post12": {
            "title": "Interesting DS / ML / DL courses to explore",
            "content": "Interesting DS / ML / DL Courses . nlp . Computer vision . Graph models . Graph Analytics for Big Data (Coursera, UC San Diego) https://www.coursera.org/learn/big-data-graph-analytics | Neo4J classes: https://neo4j.com/graphacademy/online-training/ | .",
            "url": "https://sanzgiri.com/interesting-courses",
            "relUrl": "/interesting-courses",
            "date": " • Aug 25, 2019"
        }
        
    
  
    
        ,"post13": {
            "title": "Weekly Update, Aug 25, 2019",
            "content": "Updates from week of Aug 27, 2019 . A lot of NLP related stuff: . How to code the Transformer in PyTorch: https://blog.floydhub.com/the-transformer-in-pytorch/ | Gensim wordvectors: https://radimrehurek.com/gensim/models/keyedvectors.html | BERT Tutorial: http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ | BERT as service: http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ | Transformers from scratch: http://www.peterbloem.nl/blog/transformers | NLP from Domino DataLab: https://blog.dominodatalab.com/deep-learning-illustrated-building-natural-language-processing-models/ | NLP from Scratch (Goncalves): https://github.com/dataforscience/nlp | Best Word &amp; Sentence Embeddings: https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a | Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/2 and colab: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb | Fast Sentence Embeddings: https://towardsdatascience.com/fse-2b1ffa791cf9 and code https://github.com/oborchers/Fast_Sentence_Embeddings | Word Embeddings with Spacy &amp; Gensim: https://www.shanelynn.ie/word-embeddings-in-python-with-spacy-and-gensim/ | FLAIR tutorials: https://github.com/zalandoresearch/flair/tree/master/resources/docs | Building GPT-2 https://blog.floydhub.com/gpt2/ | Grover: https://rowanzellers.com/grover/ | State of Sentiment Analysis: https://webdocs.cs.ualberta.ca/~zaiane/postscript/survey-SentimentAnalysis.pdf | . Finance/Time Series: . MLCourse.ai: https://mlcourse.ai/articles/topic9-part1-time-series/ | Alphavantage.co has free API for stock data: https://www.alphavantage.co/ | Financial ML Links: https://github.com/firmai/financial-machine-learning | ML for Asset Mgmt: https://github.com/firmai/machine-learning-asset-management | RL for Trading: https://teddykoker.com/ | Mutivariate Time Series with Keras: https://medium.com/datadriveninvestor/multivariate-time-series-using-rnn-with-keras-7f78f4488679 | . Misc . Unblocked: Book on Blockchain (not in Scribd or Liby) https://www.amazon.com/Unblocked-Blockchains-Change-Business-about/dp/0998042005/ref=sr_1_3?keywords=unblocked&amp;qid=1566796503&amp;s=gateway&amp;sr=8-3 | RAdam optimizer: https://www.amazon.com/Unblocked-Blockchains-Change-Business-about/dp/0998042005/ref=sr_1_3?keywords=unblocked&amp;qid=1566796503&amp;s=gateway&amp;sr=8-3 | FirmAI ML &amp; DS Applications in Industry: https://github.com/firmai/industry-machine-learning | WhatsApp Automation: https://medium.com/better-programming/i-wrote-a-script-to-whatsapp-my-parents-every-morning-in-just-20-lines-of-python-code-5d203c3b36c1 | Share Jupyter Notebooks: https://www.jvn.io/ | TWIML Platforms: https://s3-us-west-2.amazonaws.com/com.cloudpulsestrat/public/TWIML_ML_Platforms.pdf | Snokel : https://www.snorkel.org/hello-world-v-0-9 | Inspection Paradox: https://towardsdatascience.com/the-inspection-paradox-is-everywhere-2ef1c2e9d709 | Survival Analysis: KM and Gamma distributions: https://better.engineering/2019/07/29/modeling-conversion-rates-and-saving-millions-of-dollars-using-kaplan-meier-and-gamma-distributions | Memory Networks: https://arxiv.org/pdf/1410.3916.pdf | Jupyter Widgets: https://towardsdatascience.com/bring-your-jupyter-notebook-to-life-with-interactive-widgets-bc12e03f0916 | .",
            "url": "https://sanzgiri.com/weekly-update-082719",
            "relUrl": "/weekly-update-082719",
            "date": " • Aug 24, 2019"
        }
        
    
  
    
        ,"post14": {
            "title": "OSCON 2019 Notes",
            "content": "Notes from attending the ML Ops sessions during OSCON 2019. . Model serving pipelines using a combination of Kubeflow, Seldon-Core and Argo: | . https://docs.seldon.io/projects/seldon-core/en/latest/index.html https://argoproj.github.io/argo/ . IBM CODAIT: | . https://developer.ibm.com/code/open/centers/codait/ . IBM Data Asset Exchange: | . https://developer.ibm.com/exchanges/data/ . RedHat OpenShift Container Platform: https://www.openshift.com/products/container-platform ML Workflows: https://github.com/willb/openshift-ml-workflows-workshop . | Serverless / Algorithmia: Presentation: https://docs.google.com/presentation/d/1LNb69-dTqNCmFawuOOj1tNVZuQ1QA-Jqbj-LPunBK7w/edit#slide=id.g3974aef880_0_0 Example code: https://github.com/algorithmiaio/sample-apps/tree/master/algo-dev-demo/digit_recognition . | Kubeflow deployment example: Blog post: https://towardsdatascience.com/mlapp-419f90e8f007 . | . https://github.com/marketplace/issue-label-bot . Kubeflow pipelines: https://codelabs.developers.google.com/codelabs/cloud-kubeflow-pipelines-gis/index.html?index=../..index#0 . | Open Data Hub: https://opendatahub.io/ . | Rad Analytics: https://radanalytics.io/tutorials . | .",
            "url": "https://sanzgiri.com/oscon-2019",
            "relUrl": "/oscon-2019",
            "date": " • Jul 15, 2019"
        }
        
    
  
    
        ,"post15": {
            "title": "Weekly Update, July 22, 2019",
            "content": "Updates from week of July 22, 2019 . Similar website to Hackernews: Hacknews with tags: http://www.taggernews.com/tags/ai/machine%20learning/: List of tags: http://www.taggernews.com/tags/ | Lobsters: https://lobste.rs/ | . | Thread on free compute resources: https://news.ycombinator.com/item?id=20225118. Creating a voice assistant app on AWS / GCP to get rlling monthly credits. | Create cross-platform Alexa / Google app using https://www.jovo.tech/ | Another google action link: https://medium.com/google-cloud/building-your-first-action-for-google-home-in-30-minutes-ec6c65b7bd32 or https://developers.google.com/actions/community/overview | 100 Days of Algorithms: https://medium.com/100-days-of-algorithms/latest | Modern Algorithmic Toolbox class: http://web.stanford.edu/class/cs168/index.html | Estimating unsseen populations. May be useful to obtain distribution of bids not seen. Papers: https://theory.stanford.edu/~valiant/papers/unseenJournal.pdf (orig),https://arxiv.org/pdf/1707.03854v1.pdf (updated), code https://github.com/siddarthhari95/unseen_estimator and https://github.com/roydeb/unseen_estimator | . | Pre-trained NLP models: https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/ | New guide to Ludwig: https://blog.dominodatalab.com/a-practitioners-guide-to-deep-learning-with-ludwig/ | H2O Driverless AI recipes: https://github.com/h2oai/driverlessai-recipes | Spark NLP: https://github.com/JohnSnowLabs/spark-nlp-workshop | Azure AI Data Hackathon: https://azureai.devpost.com/ Sep 10 2019 deadline | Noah Gift AWS Lambda: https://github.com/noahgift/awslambda/blob/master/beginners_guide_aws_lambda.ipynb | New FastAI class on NLP: notebook setup: https://forums.fast.ai/t/a-code-first-introduction-to-natural-language-processing-2019/50203/2 | https://www.fast.ai/2019/07/08/fastai-nlp/ | Youtube-playlist https://www.youtube.com/playlist?list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9 | PyTorch Transformer https://blog.floydhub.com/the-transformer-in-pytorch/ | . | .",
            "url": "https://sanzgiri.com/weekly-update-072219",
            "relUrl": "/weekly-update-072219",
            "date": " • Jul 13, 2019"
        }
        
    
  
    
        ,"post16": {
            "title": "Numerai Compute on AWS",
            "content": "Train Numerai models and submit predictions from AWS . Use numerai-cli from https://github.com/numerai/numerai-cli . | Code is installed on mac laptop in ~/example-numerai . | . Install python 3.x form www.python.org curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py pip3 install -U numerai-cli # latest aws configs numerai setup -c 2048 -m 16384 # update example code numerai docker copy-example # build container, deploy on aws numerai docker deploy # Run locally and submit predictions numerai docker run # Test remote webhook numerai compute test-webhook numerai compute status numerai compute logs . AWS job is scheduled to run daily at 15:35 UTC: https://console.aws.amazon.com/ecs/home?region=us-east-1#/clusters/numerai-submission-ecs-cluster/scheduledTasks/numerai-daily . | Check AWS logs here: https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/fargate/service/numerai-submission;streamFilter=typeLogStreamPrefix . | Link to forums: https://community.numer.ai/channel/compute?utm_source=sendgrid.com&amp;utm_medium=email&amp;utm_campaign=website . | .",
            "url": "https://sanzgiri.com/numerai-aws",
            "relUrl": "/numerai-aws",
            "date": " • Jul 13, 2019"
        }
        
    
  
    
        ,"post17": {
            "title": "Weekly Update, June 23, 2019",
            "content": "Updates from week of June 23, 2019 . Sebastian Raschka’s collection of DL models: https://github.com/rasbt/deeplearning-models . | Subscribed to Data Elixir weekly newsletter: https://dataelixir.com/newsletters/ . | Also, became member at LeetCode: https://leetcode.com/ . | Mode Analytics has great SQL tutorials: https://mode.com/sql-tutorial/. Need to check out capabilities with their free Mode Studio offering. . | Hitchhiker’s guide to Python is oft-recommended. https://docs.python-guide.org/ by Kenneth Reitz creator of requests and other popular python libraries . | Scala School from Twitter: https://twitter.github.io/scala_school/ . | BaseDS archive of blog posts on Distributed Computing: https://medium.com/baseds/archive . | Designing Data-Intensive Applications book: https://martin.kleppmann.com/ . | AI Reading List: https://medium.com/@v_maini/ai-reading-list-c4753afd97a . | Sentdex sentiment analysis: http://sentdex.com/sentiment-analysis/ Check out their api. . | Gentle intro to GANs from Jason Brownlee: https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/ . | Review of twitter and other tools (free/paid) for social media research: https://blogs.lse.ac.uk/impactofsocialsciences/2019/06/18/using-twitter-as-a-data-source-an-overview-of-social-media-research-tools-2019/ Could be useful for building a social engagement metric for the NBA. . | Dive into Deep Learning with MxNet: https://www.d2l.ai/index.html . | Some VSCode for Python tutorials: https://www.youtube.com/watch?v=-nh9rCzPJ20 and https://www.youtube.com/watch?v=6YLMWU-5H9o . | Some Data Engineering articles to read: https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a and this series of articles: https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7 . | .",
            "url": "https://sanzgiri.com/weekly-update-062319",
            "relUrl": "/weekly-update-062319",
            "date": " • Jun 22, 2019"
        }
        
    
  
    
        ,"post18": {
            "title": "Weekly Update, June 16, 2019",
            "content": "Starting a weekly blog update with new things learnt in the week . James Clear, author of Atomic Habits, has a great collection of inspiring talks here: https://jamesclear.com/great-speeches . | Kaggle Days 2019 SFO Playlist: https://www.youtube.com/playlist?list=PLqFaTIg4myu99Huiyr2ZojzN3dlYhe8rf . | FastAI - Austria study group has a repo with starter material on fastai &amp; pytorch here: https://github.com/MicPie/fastai-pytorch-course-vienna . | Cheat sheets by the Amidi brothers at Stanford, on Deep Learning and other topics: https://stanford.edu/~shervine/teaching/ . | Nice set of articles on creating a RL gym environment for bitcoin trading: Part 1: https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29 | Part 2: https://towardsdatascience.com/using-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b | . | Optimus library that makes spark dataframes easy to use (similar to pandas): https://github.com/ironmussa/Optimus | See here for a cheat sheet: https://htmlpreview.github.io/?https://github.com/ironmussa/Optimus/blob/master/docs/cheatsheet/optimus_cheat_sheet.html . | Tensorflow Meets playlist: https://www.youtube.com/playlist?list=PLQY2H8rRoyvyOeER8UNF-1zXaCKGLZVog | In particular, on tensorflow datasets: https://www.youtube.com/watch?v=QAlgqmttan0&amp;list=PLQY2H8rRoyvyOeER8UNF-1zXaCKGLZVog&amp;index=3&amp;t=0s . | Pipeline AI for deployment of ML models: https://github.com/PipelineAI/pipeline/tree/master/docs/quickstart/docker. Recording of workshop is here: https://www.youtube.com/watch?v=OhIa2cnGD8Y . | Peter Norvig’s talk at Microsoft: https://www.microsoft.com/en-us/research/video/as-we-may-program/ . | Count Bayesie blog: https://www.countbayesie.com/blog/2016/5/1/a-guide-to-bayesian-statistics . | Summer of AI tutorial on Pytorch: https://summerofai.com/lessons/ . | Clickbait analysis: https://www.linkedin.com/pulse/clickbaits-revisited-deep-learning-title-content-features-thakur/ . | Numerai submissions on EC2 Fargate | .",
            "url": "https://sanzgiri.com/weekly-update-061619",
            "relUrl": "/weekly-update-061619",
            "date": " • Jun 15, 2019"
        }
        
    
  
    
        ,"post19": {
            "title": "Tensorflow in Swift",
            "content": "Using Swift on Tensorflow . Lauching a Jupyter notebook for Swift git clone https://github.com/google/swift-jupyter.git cd swift-jupyter docker build -f docker/Dockerfile -t swift-jupyter . docker run -p 8888:8888 -it --cap-add SYS_PTRACE -v ~/swift-notebooks:/notebooks swift-jupyter . | Useful resources: Swift for Tensorflow project on github: https://github.com/tensorflow/swift | Swift kernels in Jupyter: https://github.com/google/swift-jupyter/#option-3-using-the-docker-container | Fast AI swift notebooks: https://github.com/fastai/fastai_docs/tree/master/dev_swift | Hacking with Swift: https://www.hackingwithswift.com | Swift for Tensorflow example: https://colab.research.google.com/github/tensorflow/swift/blob/master/docs/site/tutorials/model_training_walkthrough.ipynb | | .",
            "url": "https://sanzgiri.com/tensorflow-swift",
            "relUrl": "/tensorflow-swift",
            "date": " • May 19, 2019"
        }
        
    
  
    
        ,"post20": {
            "title": "Using VS Code",
            "content": "Notes on using VS Code . Start here: https://scotch.io/courses/make-visual-studio-code-your-editor/introduction | .",
            "url": "https://sanzgiri.com/using-vscode",
            "relUrl": "/using-vscode",
            "date": " • Jan 7, 2019"
        }
        
    
  
    
        ,"post21": {
            "title": "Setting up a home server",
            "content": "Using DDNS to set up remote access to home server . Following instructions at https://www.howtogeek.com/66438/how-to-easily-access-your-home-network-from-anywhere-with-ddns/ | I selected DYNU as the Dynamic DNS Service provider and created an account with them: https://www.dynu.com/en-US/. This is a free service and you can get a domain (I chose sanzgiri.freeddns.org) and IPv4 address | Remote SSH to your machine is as easy as | . ssh -A ashutosh@sanzgiri.freeddns.org . You can remotely suspend your machine using | . ssh -t ashutosh@sanzgiri.freeddns.org sudo systemctl suspend . You can remotely wake up your machine using | . wakeonlan -p 4343 &lt;mac-address&gt; . Note that you need to enable wakeonlan on your motherboard in your BIOS setup. wakeonlan is a perl utility available from | . https://github.com/jpoliv/wakeonlan/blob/master/wakeonlan. You can also the “Mocha WOL” app on iOS. .",
            "url": "https://sanzgiri.com/setting-up-home-server",
            "relUrl": "/setting-up-home-server",
            "date": " • Dec 7, 2018"
        }
        
    
  
    
        ,"post22": {
            "title": "Using ngrok",
            "content": "Using ngrok for remote access to your home machine . ngrok (https://ngrok.com/) is a great way to connect to a web server (e.g jupyter notebook server) on your home machine or simply ssh into it. A basic account is free. When you register, you will get an authtoken. Use that to create a config file on your home machine: . ngrok authtoken &lt;YOUR-AUTH-TOKEN&gt; . This puts the authtoken in ~/.ngrok2/ngrok.yml. Edit this file and add the following lines: . tunnels: http: proto: http addr: 8888 ssh: proto: tcp addr: 22 . Next, start ngrok using: . ngrok start --all . Once you do this, you get a monitoring display that lists the forwarding addresses. At this point, you can point your browser to https://&lt;your-address&gt;.ngrok.io to connect to your Jupyter notebook. . To ssh to your machine, you will have to use the syntax: ssh &lt;user&gt;@0.tcp.ngrok.io -p &lt;xxxxx&gt; where p is the forwarding port you see on the monitoring screen. .",
            "url": "https://sanzgiri.com/using-ngrok",
            "relUrl": "/using-ngrok",
            "date": " • Jun 1, 2018"
        }
        
    
  
    
        ,"post23": {
            "title": "Fastai Lesson 2",
            "content": "Notes from Lesson 2 . sz =&gt; image_size, bs =&gt; batch_size, precompute =&gt; use_precomputed_activations ps =&gt; dropout_probabilities, aug_tfms =&gt; augmentation_transforms . precompute=True means activations have already been computed (use previous weights). It caches some of the intermediate steps which we do not need to recalculate every time. It uses cached non-augmented activations. That’s why data augmentation doesn’t work with precompute. Having precompute speeds up our work. . | I think one fundamental difference between a pre-trained network and a pre-computed outputs, is that: . In a pre-trained network the layer weights that have been pre-calculated, but this has nothing to do with your input data with the training/test/validation images of dogs and cats Pre-computed activations have passed your input data (dogs and cat images) through the network and have cached the results. It seems like pre-computing is a second level caching mechanism to avoid repeated feedforward passes on the input data, since it will end up producing the same results each time. The danger is that if you make some tweaks (like data augmentation), and you forget to re-run the pre-compute phase, then your changes won’t be reflected. . | With Data Augmentation, set precompute=False . | Set precompute=False when freezing, should be done automatically . | .",
            "url": "https://sanzgiri.com/fastai-lesson2",
            "relUrl": "/fastai-lesson2",
            "date": " • Jun 1, 2018"
        }
        
    
  
    
        ,"post24": {
            "title": "Fastai Lesson 1",
            "content": "Notes . environment.yml has pytorch&lt;0.4 which causes pytorch to not get updated if pytorch is not already installed. Had to do the following: | also had to install fastai manually | also installing some other useful libraries pip install --force pytorch pip install fastai pip install gpustat pip install google-images-download . | download google chromedriver wget https://chromedriver.storage.googleapis.com/2.39/chromedriver_linux64.zip unzip chromedriver.zip sudo mv chromedriver /usr/local/bin . | . Explorations . Use https://github.com/boxabirds/fastai-helpers to create new dataset: | . wget https://raw.githubusercontent.com/boxabirds/fastai-helpers/master/training-data-generator.py . This package uses https://github.com/hardikvasa/google-images-download . You can use this as follows to download 200 images of horse and hippo in subdirectory data horsehippo with train-valid split of 80-20 (note no spaces after the comma between category names, supports &gt; 2 categories): | . python training-data-generator.py -d data/horsehippo -s &quot;horse,hippo&quot; -q 200 -v 20 . A faster option to generate a dataset is to use https://github.com/prairie-guy/ai_utilities. A sample workflow would be as follows: git clone https://github.com/prairie-guy/ai_utilities.git cd ai_utilities/ tar xvzf geckodriver-v0.19.1-linux64.tar.gz sudo mv geckodriver /usr/local/bin . | . python image_download.py &#39;horse&#39; 200 --engine &#39;google&#39; python image_download.py &#39;hippo&#39; 200 --engine &#39;google&#39; mv dataset horsehippo2 ./filter_img.sh horsehippo2/horse ./filter_img.sh horsehippo2/hippo python make_train_valid.py horsehippo2 --train 0.7 --valid 0.15 --test 0.15 mv horsehippo2 ~/fastai/courses/dl1/data/ .",
            "url": "https://sanzgiri.com/fastai-lesson1",
            "relUrl": "/fastai-lesson1",
            "date": " • Jun 1, 2018"
        }
        
    
  
    
        ,"post25": {
            "title": "Using Aws Cloud9 On Home Server",
            "content": "Setting up AWS Cloud 9 to ssh to your home Ubuntu server . Prepare your home Ubuntu server . Set up port forwarding on your home router. You want to forward tcp port 22. Ideally, you want to forward it to non-standard port (say, 2220). For now, to keep things simple (but perhaps insecure), I just forwarded it to 22. The process for doing this is router-specific. As part of doing this, you also have to reserve the IP address for your . | Get the public ip address of your machine. There are several ways to do this: wget -qO- http://ipecho.net/plain ; echo curl ipinfo.io/ip . | Install nodejs on your home server: curl -sL https://deb.nodesource.com/setup_9.x | sudo -E bash - sudo apt-get install -y nodejs . | Set up permissions on your home directory: sudo chmod u=rwx,g=rx,o=rx ~ . | You need to have python v2.7 in your path (check how critical this requirement is and what happens if you have version v3.x instead) | . Setup on AWS . Login to your AWS console at https://console.aws.amazon.com/cloud9/home?region=us-east-1 (or appropriate region) . | Click “Create Environment” . | Select “Connect and run in remote server (SSH)” . | Enter your login name on your server under “User” . | Enter your server’s public IP which you found above, under “Host” . | Port is the port to which you forwarded port 22 of your server above. . | Copy SSH key to your clipboard. Create or append the key to file .ssh/authorized_keys . | Set permission on this file to 600 chmod 600 .ssh/authorized_keys . | Skip “Advanced Settings” for now . | Click “Next Step”. Here you will be able to review your settings and launch your development environment. You will be asked to confirm whether some tools can be installed on your server. Go ahead and accept. . | Voila, in a few minutes, you will have an amazing IDE for remote development on your home server. | .",
            "url": "https://sanzgiri.com/using-AWS-Cloud9-on-home-server",
            "relUrl": "/using-AWS-Cloud9-on-home-server",
            "date": " • Jan 31, 2018"
        }
        
    
  
    
        ,"post26": {
            "title": "Google Aiy Voice",
            "content": "Adventures with Google AIY Voice Kit . Raspberry Pi setup notes . Choose an 8 GB or larger SD card and fastest possible (class 10 or higher) | Run sudo raspi-config and change the following: Update | Change default user password | Change hostname | Overclock: set to Turbo | Localization: set Timezone | Interfacing Options: enable ssh, camera | Advanced Options: Expand Filesystem | Boot Options: Console AutoLogin | . |",
            "url": "https://sanzgiri.com/google-aiy-voice",
            "relUrl": "/google-aiy-voice",
            "date": " • Dec 31, 2017"
        }
        
    
  
    
        ,"post27": {
            "title": "My First Blog Post",
            "content": "How this blog was created . Fork github repo adeshpande3/adeshpande3.github.io and rename it as username.github.io where username is your github username . | In this repo, edit file _config.yml and update name, description (this is what appears below your name on your blog), avatar, footer-links, url. You can edit this file from github itself . | Create a _posts directory at the top level of this repo (if one does not exist). You can do this by create new file from the github repo page with the name “/_posts” . | As the title indicates, this directory will contain your blog posts as separate files. Files should be named using the convention YYYY-MM-DD-title.md where spaces in the title name are replace by hyphens (e.g. 2017-12-17-my-first-blog-post.md) . | The blog post is written in markdown syntax. I use prose.io as an online markdown editor. After you have composed and previewed your post, take a look at the metadata using the icon on the right. Here you can provide the excerpt for your blog post as well as direct link to it in the permalink (e.g. “/my-first-blog-post”) . | Once you save your changes in prose.io, it will take a couple of minutes for your posts to show up on username.github.io . | In order to allow comments on your blog, you will have to create a disqus account. Within disqus, select “I want to install Disqus on my site”. The website name you provide here is your disqus shortname. After going through this, go back to your github.io repo and update the disqus_shortname variable in the file _includes/disqus.html . |",
            "url": "https://sanzgiri.com/my-first-blog-post",
            "relUrl": "/my-first-blog-post",
            "date": " • Dec 16, 2017"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Bio . List of Publications . Conferences Attended . Projects . What I am reading .",
          "url": "https://sanzgiri.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Projects",
          "content": "",
          "url": "https://sanzgiri.com/projects/",
          "relUrl": "/projects/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sanzgiri.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}